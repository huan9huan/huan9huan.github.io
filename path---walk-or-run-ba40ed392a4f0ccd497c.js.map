{"version":3,"sources":["webpack:///path---walk-or-run-ba40ed392a4f0ccd497c.js","webpack:///./.cache/json/walk-or-run.json"],"names":["webpackJsonp","406","module","exports","data","site","siteMetadata","title","author","markdownRemark","id","html","frontmatter","date","pathContext","slug","previous","fields","next"],"mappings":"AAAAA,cAAc,gBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,MAAQC,cAAgBC,MAAA,eAAAC,OAAA,eAA8CC,gBAAmBC,GAAA,6FAAAC,KAAA,ugRAAmtPC,aAAk/BL,MAAA,eAAAM,KAAA,qBAAkDC,aAAgBC,KAAA,gBAAAC,UAAmCC,QAAUF,KAAA,yBAA+BH,aAAgBL,MAAA,wBAA+BW,MAASD,QAAUF,KAAA,aAAmBH,aAAgBL,MAAA","file":"path---walk-or-run-ba40ed392a4f0ccd497c.js","sourcesContent":["webpackJsonp([14284542517335],{\n\n/***/ 406:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"site\":{\"siteMetadata\":{\"title\":\"huan9huan的博客\",\"author\":\"huang huan\"}},\"markdownRemark\":{\"id\":\"/Users/alhuang/work/blog/src/pages/walk-or-run/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p>本文主要实践了一个完成的DeepLearning的最小工作集</p>\\n<blockquote>\\n<ol>\\n<li>构造测试数据集</li>\\n<li>做训练</li>\\n</ol>\\n</blockquote>\\n<p>问题是：能够找到一些图片，区分出图片是走路还是跑步 (walk or run)。</p>\\n<h2>1. 构造训练集</h2>\\n<p>做了一个快速构造训练集的工具 - 一个基于chrome的插件，在google images中可以快速的选择图片集，然后定义标签，上传到google storage中:</p>\\n<p>\\n  <a\\n    class=\\\"gatsby-resp-image-link\\\"\\n    href=\\\"/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-b042b.jpg\\\"\\n    style=\\\"display: block\\\"\\n    target=\\\"_blank\\\"\\n    rel=\\\"noopener\\\"\\n  >\\n  \\n  <span\\n    class=\\\"gatsby-resp-image-wrapper\\\"\\n    style=\\\"position: relative; display: block; ; max-width: 590px; margin-left: auto; margin-right: auto;\\\"\\n  >\\n    <span\\n      class=\\\"gatsby-resp-image-background-image\\\"\\n      style=\\\"padding-bottom: 95.65916398713826%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAMEBQEC/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQP/2gAMAwEAAhADEAAAAdLxHydLSyTFlKT1wP8A/8QAHBAAAgICAwAAAAAAAAAAAAAAAQIAExIhAwQQ/9oACAEBAAEFAqUlSSgCMwzxViROTT9jXn//xAAYEQADAQEAAAAAAAAAAAAAAAACE1EAEP/aAAgBAwEBPwFhXMK9/8QAGBEAAwEBAAAAAAAAAAAAAAAAAhJRABD/2gAIAQIBAT8BQZkGd//EAB4QAAEDBAMAAAAAAAAAAAAAAAABAhEQISJxMTJR/9oACAEBAAY/Auxd5yo606M5TdHx6Mp//8QAHBABAAIDAQEBAAAAAAAAAAAAAREhADFBEFFh/9oACAEBAAE/IZmBzlmj5Z4igtSyLo5ZIZkkF9yR3kkpFes4am3915//2gAMAwEAAgADAAAAEHQQfP/EABgRAAIDAAAAAAAAAAAAAAAAAAARARAx/9oACAEDAQE/EFhonK//xAAYEQADAQEAAAAAAAAAAAAAAAAAAREQIf/aAAgBAgEBPxCwkGu5/8QAHBABAAMAAgMAAAAAAAAAAAAAAQARITGBQVGR/9oACAEBAAE/EBBEcgjUb2W6sVwBV/RA6XLS8FmZ3MZwCzaqceM+xycZEKkFSLrNvSocpBb0EZ//2Q=='); background-size: cover; display: block;\\\"\\n    >\\n      <img\\n        class=\\\"gatsby-resp-image-image\\\"\\n        style=\\\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\\\"\\n        alt=\\\"image crawler\\\"\\n        title=\\\"\\\"\\n        src=\\\"/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-f8fb9.jpg\\\"\\n        srcset=\\\"/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-e8976.jpg 148w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-63df2.jpg 295w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-f8fb9.jpg 590w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-85e3d.jpg 885w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-d1924.jpg 1180w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-b042b.jpg 1244w\\\"\\n        sizes=\\\"(max-width: 590px) 100vw, 590px\\\"\\n      />\\n    </span>\\n  </span>\\n  \\n  </a>\\n    </p>\\n<p>基于这个工具, 大约花了半小时时间，在google image中搜索”run”, “walk”, “run outside” , “walk outside”等，获得到约600张图片。</p>\\n<p>然后上传到了 <a href=\\\"https://www.kaggle.com/huan9huan/walk-or-run\\\">kaggle dataset</a>中：\\n\\n  <a\\n    class=\\\"gatsby-resp-image-link\\\"\\n    href=\\\"/static/banner-20f2705a92d70b9cf3b47b85702cec06-47884.png\\\"\\n    style=\\\"display: block\\\"\\n    target=\\\"_blank\\\"\\n    rel=\\\"noopener\\\"\\n  >\\n  \\n  <span\\n    class=\\\"gatsby-resp-image-wrapper\\\"\\n    style=\\\"position: relative; display: block; ; max-width: 590px; margin-left: auto; margin-right: auto;\\\"\\n  >\\n    <span\\n      class=\\\"gatsby-resp-image-background-image\\\"\\n      style=\\\"padding-bottom: 21.052631578947366%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAAcUlEQVQY05WPMQ5AERBEHVKCuzgD99IIWolaolEqmB8SKv8nf5qdbN5OZgle1HtfM4SA1trxtdblxxjXO3JbbngGMcagtUaMEZxzeO8PcwslX+1SSqCUQkoJpRSEEMg5/w/cYCkFzrnVyloLY8znu1MPXkItP/Jwk60AAAAASUVORK5CYII='); background-size: cover; display: block;\\\"\\n    >\\n      <img\\n        class=\\\"gatsby-resp-image-image\\\"\\n        style=\\\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\\\"\\n        alt=\\\"image crawler\\\"\\n        title=\\\"\\\"\\n        src=\\\"/static/banner-20f2705a92d70b9cf3b47b85702cec06-fb8a0.png\\\"\\n        srcset=\\\"/static/banner-20f2705a92d70b9cf3b47b85702cec06-1a291.png 148w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-2bc4a.png 295w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-fb8a0.png 590w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-526de.png 885w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-fa2eb.png 1180w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-08f6a.png 1770w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-47884.png 1900w\\\"\\n        sizes=\\\"(max-width: 590px) 100vw, 590px\\\"\\n      />\\n    </span>\\n  </span>\\n  \\n  </a>\\n    </p>\\n<h2>训练 - 使用DenseNet做fine tuning</h2>\\n<p>直接说结果，使用keras的DenseNet的pre-trained的模型，加上一个inception的结构作为head model来进一步的提取DenseNet的feature，获得到了 <strong>90%</strong> 的成功率（validation dataset上）。kernels参见 <a href=\\\"https://www.kaggle.com/huan9huan/walk-or-run-fine-tuning?scriptVersionId=5052538\\\">walk or run, fine tuning\\n</a></p>\\n<p>具体来说:</p>\\n<h3>1.数据分割</h3>\\n<blockquote>\\n<ol>\\n<li>80%训练集（train dataset）</li>\\n<li>20%交叉测试集（validation dataset）</li>\\n</ol>\\n</blockquote>\\n<h3>2. 模型构造：</h3>\\n<div class=\\\"gatsby-highlight\\\">\\n      <pre class=\\\"language-text\\\"><code class=\\\"language-text\\\"># build model\\n\\ndef conv2d_bn(x,\\n              filters,\\n              num_row,\\n              num_col,\\n              padding=&#39;same&#39;,\\n              strides=(1, 1),\\n              name=None):\\n    filters = int(filters)\\n    x = Conv2D(\\n        filters, (num_row, num_col),\\n        strides=strides,\\n        padding=padding,\\n        use_bias=False,\\n        name=name + &quot;_conv&quot;)(x)\\n    x = BatchNormalization(scale=False, name=name + &quot;_bn&quot;)(x)\\n    x = Activation(&#39;relu&#39;, name=name)(x)\\n    return x \\n\\ndef incept(x, name=&quot;incept&quot;, scale=1):\\n    branch1x1 = conv2d_bn(x, 64 // scale, 1, 1, name = name + &quot;-1x1&quot;)\\n\\n    branch5x5 = conv2d_bn(x, 48 // scale , 1, 1, name = name + &quot;-5x5-1x1&quot;)\\n    branch5x5 = conv2d_bn(branch5x5, 64 // scale, 5, 5, name = name + &quot;-5x5-5x5&quot;)\\n\\n    branch3x3dbl = conv2d_bn(x, 64 // scale, 1, 1, name = name + &quot;-3x3-1x1&quot;)\\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96 // scale, 3, 3, name = name + &quot;-3x3-3x3-1&quot;)\\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96 // scale, 3, 3, name = name + &quot;-3x3-3x3-2&quot;)\\n\\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding=&#39;same&#39;)(x)\\n    branch_pool = conv2d_bn(branch_pool, 32 // scale, 1, 1, name = name + &quot;-pool&quot;)\\n    return concatenate(\\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\\n        name= name + &#39;-all&#39;)\\n  \\ndef build_head_model(input_shape, n_classes = 2):\\n    head_input = Input(shape=input_shape, name = &#39;head_input&#39;)\\n    x = head_input\\n    x = Dropout(0.8)(x)\\n    x = incept(x, name=&quot;i2&quot;, scale=2)\\n    x = Flatten()(x)\\n    x = Dropout(0.8)(x)\\n    x = Dense(n_classes, activation=&#39;softmax&#39;, name=&#39;prediction&#39;)(x)\\n    return Model(input = head_input, output = x, name=&quot;dogs_ft_head_model&quot;)\\n  \\ndef build_model(pretrained_model_name, n_classes):\\n    input = Input(shape=(224,224,3), name = &#39;image_input&#39;)\\n    x = input\\n    pretrained_model, _, preprocess = load_base(pretrained_model_name)\\n    for layer in pretrained_model.layers[:-1]:\\n        layer.trainable = False\\n    \\n    x = pretrained_model(x)\\n    head_model = build_head_model(x.get_shape()[1:].as_list(), n_classes)\\n    x = head_model(x)\\n  \\n    model = Model(input = input, output = x)\\n    model.compile(metrics=[&quot;accuracy&quot;],\\n                  loss=&quot;categorical_crossentropy&quot;,\\n                  optimizer=optimizers.Adadelta())\\n    \\n    return model, head_model, preprocess</code></pre>\\n      </div>\\n<h3>3. 其他的一些超参：</h3>\\n<blockquote>\\n<ol>\\n<li>batch size: 32</li>\\n<li>steps each epoch: 160</li>\\n<li>优化器是Adadelta，缺省参数</li>\\n</ol>\\n</blockquote>\\n<p><strong>注：本测试基于Google Colaboratory Notebook上提供的K80 GPU。</strong></p>\\n<h2>补充：其他的pre-trained的模型的结果</h2>\\n<blockquote>\\n<ol>\\n<li>使用了 Vgg16或者ResNet50只能得到大约80%的val accu，不过值得注意的是vgg16的val loss很低(0.48)。</li>\\n<li>使用了 InceptionResNetV2，得到了83%的成功率。</li>\\n<li>使用了 MobileNetV2，得到了84%的成功率。</li>\\n</ol>\\n</blockquote>\\n<h2>将来的工作</h2>\\n<ol>\\n<li>\\n<p>自己抓取数据的时候，由于这个数据集是反映了我自己对walk还是run的判断，可能存在系统性偏误。解决的办法是让不同的人去贡献数据，从而可以消除这种系统性偏差。</p>\\n</li>\\n<li>\\n<p>到底是什么特征在walk or run的判断做了关键的作用，也就是“why it works”的问题。一个方法是遍历数据集，然后得到walk和run的各自的最大的confidence的集合，从而比较分析这些数据的特征。</p>\\n</li>\\n<li>\\n<p>val loss和val accuracy并不一致，比如DenseNet的val loss是0.8，但是accuray是 90%，而vgg的loss是0.48，但是accuracy却是0.8左右，他们如何统一起来做模型的筛选，需要进一步的研究。</p>\\n</li>\\n</ol>\",\"frontmatter\":{\"title\":\"是走还是跑，这是一个问题\",\"date\":\"August 12, 2018\"}}},\"pathContext\":{\"slug\":\"/walk-or-run/\",\"previous\":{\"fields\":{\"slug\":\"/fine-tuning-captcha/\"},\"frontmatter\":{\"title\":\"Fine Tuning Captcha\"}},\"next\":{\"fields\":{\"slug\":\"/k8s-gfw/\"},\"frontmatter\":{\"title\":\"k8s安装的翻墙攻略\"}}}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---walk-or-run-ba40ed392a4f0ccd497c.js","module.exports = {\"data\":{\"site\":{\"siteMetadata\":{\"title\":\"huan9huan的博客\",\"author\":\"huang huan\"}},\"markdownRemark\":{\"id\":\"/Users/alhuang/work/blog/src/pages/walk-or-run/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p>本文主要实践了一个完成的DeepLearning的最小工作集</p>\\n<blockquote>\\n<ol>\\n<li>构造测试数据集</li>\\n<li>做训练</li>\\n</ol>\\n</blockquote>\\n<p>问题是：能够找到一些图片，区分出图片是走路还是跑步 (walk or run)。</p>\\n<h2>1. 构造训练集</h2>\\n<p>做了一个快速构造训练集的工具 - 一个基于chrome的插件，在google images中可以快速的选择图片集，然后定义标签，上传到google storage中:</p>\\n<p>\\n  <a\\n    class=\\\"gatsby-resp-image-link\\\"\\n    href=\\\"/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-b042b.jpg\\\"\\n    style=\\\"display: block\\\"\\n    target=\\\"_blank\\\"\\n    rel=\\\"noopener\\\"\\n  >\\n  \\n  <span\\n    class=\\\"gatsby-resp-image-wrapper\\\"\\n    style=\\\"position: relative; display: block; ; max-width: 590px; margin-left: auto; margin-right: auto;\\\"\\n  >\\n    <span\\n      class=\\\"gatsby-resp-image-background-image\\\"\\n      style=\\\"padding-bottom: 95.65916398713826%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAMEBQEC/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQP/2gAMAwEAAhADEAAAAdLxHydLSyTFlKT1wP8A/8QAHBAAAgICAwAAAAAAAAAAAAAAAQIAExIhAwQQ/9oACAEBAAEFAqUlSSgCMwzxViROTT9jXn//xAAYEQADAQEAAAAAAAAAAAAAAAACE1EAEP/aAAgBAwEBPwFhXMK9/8QAGBEAAwEBAAAAAAAAAAAAAAAAAhJRABD/2gAIAQIBAT8BQZkGd//EAB4QAAEDBAMAAAAAAAAAAAAAAAABAhEQISJxMTJR/9oACAEBAAY/Auxd5yo606M5TdHx6Mp//8QAHBABAAIDAQEBAAAAAAAAAAAAAREhADFBEFFh/9oACAEBAAE/IZmBzlmj5Z4igtSyLo5ZIZkkF9yR3kkpFes4am3915//2gAMAwEAAgADAAAAEHQQfP/EABgRAAIDAAAAAAAAAAAAAAAAAAARARAx/9oACAEDAQE/EFhonK//xAAYEQADAQEAAAAAAAAAAAAAAAAAAREQIf/aAAgBAgEBPxCwkGu5/8QAHBABAAMAAgMAAAAAAAAAAAAAAQARITGBQVGR/9oACAEBAAE/EBBEcgjUb2W6sVwBV/RA6XLS8FmZ3MZwCzaqceM+xycZEKkFSLrNvSocpBb0EZ//2Q=='); background-size: cover; display: block;\\\"\\n    >\\n      <img\\n        class=\\\"gatsby-resp-image-image\\\"\\n        style=\\\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\\\"\\n        alt=\\\"image crawler\\\"\\n        title=\\\"\\\"\\n        src=\\\"/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-f8fb9.jpg\\\"\\n        srcset=\\\"/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-e8976.jpg 148w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-63df2.jpg 295w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-f8fb9.jpg 590w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-85e3d.jpg 885w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-d1924.jpg 1180w,\\n/static/image-crawler-ba7012adccd3f2b2e56dba7985cb54bd-b042b.jpg 1244w\\\"\\n        sizes=\\\"(max-width: 590px) 100vw, 590px\\\"\\n      />\\n    </span>\\n  </span>\\n  \\n  </a>\\n    </p>\\n<p>基于这个工具, 大约花了半小时时间，在google image中搜索”run”, “walk”, “run outside” , “walk outside”等，获得到约600张图片。</p>\\n<p>然后上传到了 <a href=\\\"https://www.kaggle.com/huan9huan/walk-or-run\\\">kaggle dataset</a>中：\\n\\n  <a\\n    class=\\\"gatsby-resp-image-link\\\"\\n    href=\\\"/static/banner-20f2705a92d70b9cf3b47b85702cec06-47884.png\\\"\\n    style=\\\"display: block\\\"\\n    target=\\\"_blank\\\"\\n    rel=\\\"noopener\\\"\\n  >\\n  \\n  <span\\n    class=\\\"gatsby-resp-image-wrapper\\\"\\n    style=\\\"position: relative; display: block; ; max-width: 590px; margin-left: auto; margin-right: auto;\\\"\\n  >\\n    <span\\n      class=\\\"gatsby-resp-image-background-image\\\"\\n      style=\\\"padding-bottom: 21.052631578947366%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAAcUlEQVQY05WPMQ5AERBEHVKCuzgD99IIWolaolEqmB8SKv8nf5qdbN5OZgle1HtfM4SA1trxtdblxxjXO3JbbngGMcagtUaMEZxzeO8PcwslX+1SSqCUQkoJpRSEEMg5/w/cYCkFzrnVyloLY8znu1MPXkItP/Jwk60AAAAASUVORK5CYII='); background-size: cover; display: block;\\\"\\n    >\\n      <img\\n        class=\\\"gatsby-resp-image-image\\\"\\n        style=\\\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\\\"\\n        alt=\\\"image crawler\\\"\\n        title=\\\"\\\"\\n        src=\\\"/static/banner-20f2705a92d70b9cf3b47b85702cec06-fb8a0.png\\\"\\n        srcset=\\\"/static/banner-20f2705a92d70b9cf3b47b85702cec06-1a291.png 148w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-2bc4a.png 295w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-fb8a0.png 590w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-526de.png 885w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-fa2eb.png 1180w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-08f6a.png 1770w,\\n/static/banner-20f2705a92d70b9cf3b47b85702cec06-47884.png 1900w\\\"\\n        sizes=\\\"(max-width: 590px) 100vw, 590px\\\"\\n      />\\n    </span>\\n  </span>\\n  \\n  </a>\\n    </p>\\n<h2>训练 - 使用DenseNet做fine tuning</h2>\\n<p>直接说结果，使用keras的DenseNet的pre-trained的模型，加上一个inception的结构作为head model来进一步的提取DenseNet的feature，获得到了 <strong>90%</strong> 的成功率（validation dataset上）。kernels参见 <a href=\\\"https://www.kaggle.com/huan9huan/walk-or-run-fine-tuning?scriptVersionId=5052538\\\">walk or run, fine tuning\\n</a></p>\\n<p>具体来说:</p>\\n<h3>1.数据分割</h3>\\n<blockquote>\\n<ol>\\n<li>80%训练集（train dataset）</li>\\n<li>20%交叉测试集（validation dataset）</li>\\n</ol>\\n</blockquote>\\n<h3>2. 模型构造：</h3>\\n<div class=\\\"gatsby-highlight\\\">\\n      <pre class=\\\"language-text\\\"><code class=\\\"language-text\\\"># build model\\n\\ndef conv2d_bn(x,\\n              filters,\\n              num_row,\\n              num_col,\\n              padding=&#39;same&#39;,\\n              strides=(1, 1),\\n              name=None):\\n    filters = int(filters)\\n    x = Conv2D(\\n        filters, (num_row, num_col),\\n        strides=strides,\\n        padding=padding,\\n        use_bias=False,\\n        name=name + &quot;_conv&quot;)(x)\\n    x = BatchNormalization(scale=False, name=name + &quot;_bn&quot;)(x)\\n    x = Activation(&#39;relu&#39;, name=name)(x)\\n    return x \\n\\ndef incept(x, name=&quot;incept&quot;, scale=1):\\n    branch1x1 = conv2d_bn(x, 64 // scale, 1, 1, name = name + &quot;-1x1&quot;)\\n\\n    branch5x5 = conv2d_bn(x, 48 // scale , 1, 1, name = name + &quot;-5x5-1x1&quot;)\\n    branch5x5 = conv2d_bn(branch5x5, 64 // scale, 5, 5, name = name + &quot;-5x5-5x5&quot;)\\n\\n    branch3x3dbl = conv2d_bn(x, 64 // scale, 1, 1, name = name + &quot;-3x3-1x1&quot;)\\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96 // scale, 3, 3, name = name + &quot;-3x3-3x3-1&quot;)\\n    branch3x3dbl = conv2d_bn(branch3x3dbl, 96 // scale, 3, 3, name = name + &quot;-3x3-3x3-2&quot;)\\n\\n    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding=&#39;same&#39;)(x)\\n    branch_pool = conv2d_bn(branch_pool, 32 // scale, 1, 1, name = name + &quot;-pool&quot;)\\n    return concatenate(\\n        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\\n        name= name + &#39;-all&#39;)\\n  \\ndef build_head_model(input_shape, n_classes = 2):\\n    head_input = Input(shape=input_shape, name = &#39;head_input&#39;)\\n    x = head_input\\n    x = Dropout(0.8)(x)\\n    x = incept(x, name=&quot;i2&quot;, scale=2)\\n    x = Flatten()(x)\\n    x = Dropout(0.8)(x)\\n    x = Dense(n_classes, activation=&#39;softmax&#39;, name=&#39;prediction&#39;)(x)\\n    return Model(input = head_input, output = x, name=&quot;dogs_ft_head_model&quot;)\\n  \\ndef build_model(pretrained_model_name, n_classes):\\n    input = Input(shape=(224,224,3), name = &#39;image_input&#39;)\\n    x = input\\n    pretrained_model, _, preprocess = load_base(pretrained_model_name)\\n    for layer in pretrained_model.layers[:-1]:\\n        layer.trainable = False\\n    \\n    x = pretrained_model(x)\\n    head_model = build_head_model(x.get_shape()[1:].as_list(), n_classes)\\n    x = head_model(x)\\n  \\n    model = Model(input = input, output = x)\\n    model.compile(metrics=[&quot;accuracy&quot;],\\n                  loss=&quot;categorical_crossentropy&quot;,\\n                  optimizer=optimizers.Adadelta())\\n    \\n    return model, head_model, preprocess</code></pre>\\n      </div>\\n<h3>3. 其他的一些超参：</h3>\\n<blockquote>\\n<ol>\\n<li>batch size: 32</li>\\n<li>steps each epoch: 160</li>\\n<li>优化器是Adadelta，缺省参数</li>\\n</ol>\\n</blockquote>\\n<p><strong>注：本测试基于Google Colaboratory Notebook上提供的K80 GPU。</strong></p>\\n<h2>补充：其他的pre-trained的模型的结果</h2>\\n<blockquote>\\n<ol>\\n<li>使用了 Vgg16或者ResNet50只能得到大约80%的val accu，不过值得注意的是vgg16的val loss很低(0.48)。</li>\\n<li>使用了 InceptionResNetV2，得到了83%的成功率。</li>\\n<li>使用了 MobileNetV2，得到了84%的成功率。</li>\\n</ol>\\n</blockquote>\\n<h2>将来的工作</h2>\\n<ol>\\n<li>\\n<p>自己抓取数据的时候，由于这个数据集是反映了我自己对walk还是run的判断，可能存在系统性偏误。解决的办法是让不同的人去贡献数据，从而可以消除这种系统性偏差。</p>\\n</li>\\n<li>\\n<p>到底是什么特征在walk or run的判断做了关键的作用，也就是“why it works”的问题。一个方法是遍历数据集，然后得到walk和run的各自的最大的confidence的集合，从而比较分析这些数据的特征。</p>\\n</li>\\n<li>\\n<p>val loss和val accuracy并不一致，比如DenseNet的val loss是0.8，但是accuray是 90%，而vgg的loss是0.48，但是accuracy却是0.8左右，他们如何统一起来做模型的筛选，需要进一步的研究。</p>\\n</li>\\n</ol>\",\"frontmatter\":{\"title\":\"是走还是跑，这是一个问题\",\"date\":\"August 12, 2018\"}}},\"pathContext\":{\"slug\":\"/walk-or-run/\",\"previous\":{\"fields\":{\"slug\":\"/fine-tuning-captcha/\"},\"frontmatter\":{\"title\":\"Fine Tuning Captcha\"}},\"next\":{\"fields\":{\"slug\":\"/k8s-gfw/\"},\"frontmatter\":{\"title\":\"k8s安装的翻墙攻略\"}}}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/walk-or-run.json\n// module id = 406\n// module chunks = 14284542517335"],"sourceRoot":""}